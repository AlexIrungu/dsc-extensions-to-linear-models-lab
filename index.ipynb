{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extensions to Linear Models - Lab"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","You will be able to:\n","\n","- Build a linear regression model with interactions and polynomial features \n","- Use feature selection to obtain the optimal subset of features in a dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started!\n","\n","Below we import all the necessary packages for this lab."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","from itertools import combinations\n","\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression, Lasso\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures"]},{"cell_type":"markdown","metadata":{},"source":["Load the data."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","# Load data from CSV\n","df = pd.read_csv(\"ames.csv\")\n","# Subset columns\n","df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n","         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n","         'GarageArea', 'Fireplaces', 'SalePrice']]\n","\n","# Split the data into X and y\n","y = df['SalePrice']\n","X = df.drop(columns='SalePrice')\n","\n","# Split into train, test, and validation sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Build a Baseline Housing Data Model"]},{"cell_type":"markdown","metadata":{},"source":["Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n","\n","Next steps:\n","\n","- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n","- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>-0.532331</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.510628</td>\n","      <td>-0.897228</td>\n","      <td>-0.808132</td>\n","      <td>-1.353116</td>\n","      <td>-2.214167</td>\n","      <td>-0.274466</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>-0.309245</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>0.514106</td>\n","      <td>0.315353</td>\n","      <td>-0.808132</td>\n","      <td>-0.481708</td>\n","      <td>-0.365525</td>\n","      <td>0.088703</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>0.119419</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.513011</td>\n","      <td>-0.899947</td>\n","      <td>1.684999</td>\n","      <td>0.796096</td>\n","      <td>0.866903</td>\n","      <td>-0.207566</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>819</th>\n","      <td>-0.002718</td>\n","      <td>-0.099842</td>\n","      <td>1.304613</td>\n","      <td>-0.889542</td>\n","      <td>-1.329516</td>\n","      <td>0.783758</td>\n","      <td>-0.290233</td>\n","      <td>-0.365525</td>\n","      <td>-0.852668</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td>0.086287</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>0.433080</td>\n","      <td>0.179414</td>\n","      <td>-0.808132</td>\n","      <td>-0.579400</td>\n","      <td>-0.365525</td>\n","      <td>-0.675863</td>\n","      <td>2.170867</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>821 rows Ã— 10 columns</p>\n","</div>"],"text/plain":["      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0   -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1   -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3   -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4   -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","..        ...          ...          ...          ...       ...       ...   \n","816 -0.532331    -0.099842    -0.509252    -0.510628 -0.897228 -0.808132   \n","817 -0.309245    -0.099842    -0.509252     0.514106  0.315353 -0.808132   \n","818  0.119419     0.632038    -0.509252    -0.513011 -0.899947  1.684999   \n","819 -0.002718    -0.099842     1.304613    -0.889542 -1.329516  0.783758   \n","820  0.086287    -0.099842     0.397681     0.433080  0.179414 -0.808132   \n","\n","     GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0     0.499114      0.250689    0.327629   -0.994820  \n","1    -0.247249     -0.365525    0.079146   -0.994820  \n","2    -0.944766     -0.981739   -1.105931   -0.994820  \n","3    -1.146010     -0.981739   -1.134602    0.588023  \n","4    -0.481708      0.250689   -2.281450   -0.994820  \n","..         ...           ...         ...         ...  \n","816  -1.353116     -2.214167   -0.274466    0.588023  \n","817  -0.481708     -0.365525    0.088703   -0.994820  \n","818   0.796096      0.866903   -0.207566    0.588023  \n","819  -0.290233     -0.365525   -0.852668   -0.994820  \n","820  -0.579400     -0.365525   -0.675863    2.170867  \n","\n","[821 rows x 10 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Scale X_train and X_val using StandardScaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","# Ensure X_train and X_val are scaled DataFrames\n","# (hint: you can set the columns using X.columns)\n","X_train = pd.DataFrame(X_train_scaled, columns=X.columns)\n","x_val = pd.DataFrame(X_val_scaled, columns=X.columns)\n","\n","X_train\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["(0.7868344817421309, -2301787.8249637415)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Create a LinearRegression model and fit it on scaled training data\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","# Calculate a baseline r-squared score on training data\n","baseline_train = linreg.score(X_train, y_train)\n","baseline_val = linreg.score(X_val, y_val)\n","\n","baseline_train, baseline_val"]},{"cell_type":"markdown","metadata":{},"source":["## Add Interactions\n","\n","Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n","\n","### Find the Best Interactions\n","\n","Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n","\n","***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n","\n","Print the 7 interactions that result in the highest $R^2$ scores."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 7 interactions: [(('1stFlrSF', 'Fireplaces'), -1729473.9372425335), (('TotalBsmtSF', 'Fireplaces'), -1882649.7448176094), (('GarageArea', 'Fireplaces'), -2002405.8581155958), (('OverallQual', 'TotRmsAbvGrd'), -2060919.6666263596), (('TotRmsAbvGrd', 'Fireplaces'), -2084329.697906163), (('OverallQual', 'Fireplaces'), -2245515.610545067), (('GrLivArea', 'Fireplaces'), -2250938.4385458687)]\n"]}],"source":["# Your code here\n","\n","# Set up data structure\n","interactions = []\n","\n","# Find combinations of columns and loop over them\n","column_pairs = list(combinations(X_train.columns, 2))\n","for (col1, col2) in column_pairs:\n","    # Make copies of X_train and X_val\n","    features_train = X_train.copy()\n","    features_val = X_val.copy()\n","    \n","    # Add interaction term to data\n","    features_train['interaction'] = features_train[col1] * features_train[col2]\n","    features_val['interaction'] = features_val[col1] * features_val[col2]\n","    \n","    # Find r-squared score (fit on training data, evaluate on validation data)\n","    score = LinearRegression().fit(features_train, y_train).score(features_val, y_val)\n","\n","    \n","    # Append to data structure\n","    interactions.append(((col1, col2), score))\n","    \n","# Sort and subset the data structure to find the top 7\n","top_7 = sorted(interactions, key=lambda record: record[1], reverse=True)[:7]\n","print(\"Top 7 interactions:\", top_7)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Interactions\n","\n","Write code to include the 7 most important interactions in `X_train` and `X_val` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","      <th>1stFlrSF_Fireplaces</th>\n","      <th>TotalBsmtSF_Fireplaces</th>\n","      <th>GarageArea_Fireplaces</th>\n","      <th>OverallQual_TotRmsAbvGrd</th>\n","      <th>TotRmsAbvGrd_Fireplaces</th>\n","      <th>OverallQual_Fireplaces</th>\n","      <th>GrLivArea_Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","      <td>0.800620</td>\n","      <td>0.636004</td>\n","      <td>-0.325932</td>\n","      <td>-0.025029</td>\n","      <td>-0.249390</td>\n","      <td>0.099325</td>\n","      <td>-0.496529</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","      <td>-0.638285</td>\n","      <td>-0.833866</td>\n","      <td>-0.078736</td>\n","      <td>-0.231026</td>\n","      <td>0.363632</td>\n","      <td>-0.628764</td>\n","      <td>0.245968</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","      <td>0.327296</td>\n","      <td>0.012495</td>\n","      <td>1.100202</td>\n","      <td>0.816535</td>\n","      <td>0.976654</td>\n","      <td>0.827414</td>\n","      <td>0.939872</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","      <td>-0.358127</td>\n","      <td>-0.199366</td>\n","      <td>-0.667173</td>\n","      <td>0.816535</td>\n","      <td>-0.577286</td>\n","      <td>-0.489072</td>\n","      <td>-0.673881</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","      <td>1.309105</td>\n","      <td>2.518386</td>\n","      <td>2.269632</td>\n","      <td>-0.391978</td>\n","      <td>-0.249390</td>\n","      <td>1.555503</td>\n","      <td>0.479213</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>-0.532331</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.510628</td>\n","      <td>-0.897228</td>\n","      <td>-0.808132</td>\n","      <td>-1.353116</td>\n","      <td>-2.214167</td>\n","      <td>-0.274466</td>\n","      <td>0.588023</td>\n","      <td>-0.527591</td>\n","      <td>-0.300261</td>\n","      <td>-0.161392</td>\n","      <td>0.221068</td>\n","      <td>-1.301982</td>\n","      <td>-0.058710</td>\n","      <td>-0.795664</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>-0.309245</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>0.514106</td>\n","      <td>0.315353</td>\n","      <td>-0.808132</td>\n","      <td>-0.481708</td>\n","      <td>-0.365525</td>\n","      <td>0.088703</td>\n","      <td>-0.994820</td>\n","      <td>-0.313720</td>\n","      <td>-0.511443</td>\n","      <td>-0.088243</td>\n","      <td>0.036495</td>\n","      <td>0.363632</td>\n","      <td>0.099325</td>\n","      <td>0.479213</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>0.119419</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.513011</td>\n","      <td>-0.899947</td>\n","      <td>1.684999</td>\n","      <td>0.796096</td>\n","      <td>0.866903</td>\n","      <td>-0.207566</td>\n","      <td>0.588023</td>\n","      <td>-0.529190</td>\n","      <td>-0.301663</td>\n","      <td>-0.122054</td>\n","      <td>0.547915</td>\n","      <td>0.509759</td>\n","      <td>0.371653</td>\n","      <td>0.468123</td>\n","    </tr>\n","    <tr>\n","      <th>819</th>\n","      <td>-0.002718</td>\n","      <td>-0.099842</td>\n","      <td>1.304613</td>\n","      <td>-0.889542</td>\n","      <td>-1.329516</td>\n","      <td>0.783758</td>\n","      <td>-0.290233</td>\n","      <td>-0.365525</td>\n","      <td>-0.852668</td>\n","      <td>-0.994820</td>\n","      <td>1.322629</td>\n","      <td>0.884934</td>\n","      <td>0.848252</td>\n","      <td>0.036495</td>\n","      <td>0.363632</td>\n","      <td>0.099325</td>\n","      <td>0.288730</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td>0.086287</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>0.433080</td>\n","      <td>0.179414</td>\n","      <td>-0.808132</td>\n","      <td>-0.579400</td>\n","      <td>-0.365525</td>\n","      <td>-0.675863</td>\n","      <td>2.170867</td>\n","      <td>0.389483</td>\n","      <td>0.940160</td>\n","      <td>-1.467208</td>\n","      <td>0.036495</td>\n","      <td>-0.793507</td>\n","      <td>-0.216744</td>\n","      <td>-1.257800</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>821 rows Ã— 17 columns</p>\n","</div>"],"text/plain":["      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0   -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1   -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3   -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4   -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","..        ...          ...          ...          ...       ...       ...   \n","816 -0.532331    -0.099842    -0.509252    -0.510628 -0.897228 -0.808132   \n","817 -0.309245    -0.099842    -0.509252     0.514106  0.315353 -0.808132   \n","818  0.119419     0.632038    -0.509252    -0.513011 -0.899947  1.684999   \n","819 -0.002718    -0.099842     1.304613    -0.889542 -1.329516  0.783758   \n","820  0.086287    -0.099842     0.397681     0.433080  0.179414 -0.808132   \n","\n","     GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  1stFlrSF_Fireplaces  \\\n","0     0.499114      0.250689    0.327629   -0.994820             0.800620   \n","1    -0.247249     -0.365525    0.079146   -0.994820            -0.638285   \n","2    -0.944766     -0.981739   -1.105931   -0.994820             0.327296   \n","3    -1.146010     -0.981739   -1.134602    0.588023            -0.358127   \n","4    -0.481708      0.250689   -2.281450   -0.994820             1.309105   \n","..         ...           ...         ...         ...                  ...   \n","816  -1.353116     -2.214167   -0.274466    0.588023            -0.527591   \n","817  -0.481708     -0.365525    0.088703   -0.994820            -0.313720   \n","818   0.796096      0.866903   -0.207566    0.588023            -0.529190   \n","819  -0.290233     -0.365525   -0.852668   -0.994820             1.322629   \n","820  -0.579400     -0.365525   -0.675863    2.170867             0.389483   \n","\n","     TotalBsmtSF_Fireplaces  GarageArea_Fireplaces  OverallQual_TotRmsAbvGrd  \\\n","0                  0.636004              -0.325932                 -0.025029   \n","1                 -0.833866              -0.078736                 -0.231026   \n","2                  0.012495               1.100202                  0.816535   \n","3                 -0.199366              -0.667173                  0.816535   \n","4                  2.518386               2.269632                 -0.391978   \n","..                      ...                    ...                       ...   \n","816               -0.300261              -0.161392                  0.221068   \n","817               -0.511443              -0.088243                  0.036495   \n","818               -0.301663              -0.122054                  0.547915   \n","819                0.884934               0.848252                  0.036495   \n","820                0.940160              -1.467208                  0.036495   \n","\n","     TotRmsAbvGrd_Fireplaces  OverallQual_Fireplaces  GrLivArea_Fireplaces  \n","0                  -0.249390                0.099325             -0.496529  \n","1                   0.363632               -0.628764              0.245968  \n","2                   0.976654                0.827414              0.939872  \n","3                  -0.577286               -0.489072             -0.673881  \n","4                  -0.249390                1.555503              0.479213  \n","..                       ...                     ...                   ...  \n","816                -1.301982               -0.058710             -0.795664  \n","817                 0.363632                0.099325              0.479213  \n","818                 0.509759                0.371653              0.468123  \n","819                 0.363632                0.099325              0.288730  \n","820                -0.793507               -0.216744             -1.257800  \n","\n","[821 rows x 17 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Loop over top 7 interactions\n","for record in top_7:\n","    # Extract column names from data structure\n","    col1, col2 = record[0]\n","    # Construct new column name\n","    new_col_name = col1 + \"_\" + col2\n","    # Add new column to X_train and X_val\n","    X_train[new_col_name] = X_train[col1] * X_train[col2]\n","    X_val[new_col_name] = X_val[col1] * X_val[col2]\n","\n","X_train"]},{"cell_type":"markdown","metadata":{},"source":["## Add Polynomials\n","\n","Now let's repeat that process for adding polynomial terms.\n","\n","### Find the Best Polynomials\n","\n","Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n","\n","We only want to include \"pure\" polynomials, so make sure no interactions are included.\n","\n","Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n","\n","`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 7 polynomials:\n","[('OverallQual_Fireplaces', 3, -616451.4226592197), ('OverallQual', 4, -629630.1507210187), ('OverallQual', 3, -633606.9466754809), ('Fireplaces', 4, -634422.9699739632), ('Fireplaces', 3, -634426.0811938854), ('Fireplaces', 2, -659077.0827317967), ('OverallQual_Fireplaces', 2, -676662.2893447005)]\n"]}],"source":["from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","import pandas as pd\n","import numpy as np\n","\n","# Set up data structure\n","polynomials = []\n","\n","# Create an imputer\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Loop over all columns\n","for col in X_train.columns:\n","    # Loop over degrees 2, 3, 4\n","    for degree in (2, 3, 4):\n","        \n","        # Make a copy of X_train and X_val\n","        features_train = X_train.copy()\n","        features_val = X_val.copy()\n","    \n","        # Instantiate PolynomialFeatures with relevant degree\n","        poly = PolynomialFeatures(degree, include_bias=False)\n","        \n","        # Fit polynomial to column and transform column\n","        col_transformed_train = pd.DataFrame(poly.fit_transform(features_train[[col]]), index=features_train.index)\n","        col_transformed_val = pd.DataFrame(poly.transform(features_val[[col]]), index=features_val.index)\n","        \n","        # Rename columns to ensure they're strings\n","        col_transformed_train.columns = [f\"{col}_poly_{i}\" for i in range(degree)]\n","        col_transformed_val.columns = [f\"{col}_poly_{i}\" for i in range(degree)]\n","        \n","        # Convert all column names to strings\n","        features_train.columns = features_train.columns.astype(str)\n","        features_val.columns = features_val.columns.astype(str)\n","        \n","        # Add polynomial to data\n","        features_train = pd.concat([features_train.drop(col, axis=1), col_transformed_train], axis=1)\n","        features_val = pd.concat([features_val.drop(col, axis=1), col_transformed_val], axis=1)\n","    \n","        # Impute missing values\n","        features_train_imputed = pd.DataFrame(imputer.fit_transform(features_train), columns=features_train.columns, index=features_train.index)\n","        features_val_imputed = pd.DataFrame(imputer.transform(features_val), columns=features_val.columns, index=features_val.index)\n","    \n","        # Align indices\n","        common_train_idx = features_train_imputed.index.intersection(y_train.index)\n","        common_val_idx = features_val_imputed.index.intersection(y_val.index)\n","        \n","        features_train_clean = features_train_imputed.loc[common_train_idx]\n","        y_train_clean = y_train.loc[common_train_idx]\n","        features_val_clean = features_val_imputed.loc[common_val_idx]\n","        y_val_clean = y_val.loc[common_val_idx]\n","    \n","        # Find r-squared score\n","        score = LinearRegression().fit(features_train_clean, y_train_clean).score(features_val_clean, y_val_clean)\n","    \n","        # Append to data structure\n","        polynomials.append((col, degree, score))\n","    \n","# Sort and subset the data structure to find the top 7\n","top_7_polynomials = sorted(polynomials, key=lambda record: record[-1], reverse=True)[:7]\n","print(\"Top 7 polynomials:\")\n","print(top_7_polynomials)"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Polynomials\n","\n","If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New shape of X_train: (821, 27)\n","New shape of X_val: (488, 27)\n"]}],"source":["from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import PolynomialFeatures\n","import pandas as pd\n","\n","# Convert to DataFrame for easier manipulation\n","top_polynomials = pd.DataFrame(top_7_polynomials, columns=[\"Column\", \"Degree\", \"R^2\"])\n","\n","# Drop duplicate columns based on Column name\n","top_polynomials.drop_duplicates(subset=\"Column\", inplace=True)\n","\n","# Create an imputer\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Loop over remaining results\n","for col, degree, _ in top_polynomials.values:\n","    # Impute missing values\n","    X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train[[col]]), columns=[col], index=X_train.index)\n","    X_val_imputed = pd.DataFrame(imputer.transform(X_val[[col]]), columns=[col], index=X_val.index)\n","    \n","    # Create polynomial terms\n","    poly = PolynomialFeatures(degree, include_bias=False)\n","    train_poly = pd.DataFrame(\n","        poly.fit_transform(X_train_imputed),\n","        columns=poly.get_feature_names_out([col]),\n","        index=X_train.index\n","    )\n","    val_poly = pd.DataFrame(\n","        poly.transform(X_val_imputed),\n","        columns=poly.get_feature_names_out([col]),\n","        index=X_val.index\n","    )\n","    \n","    # Concat back to original\n","    X_train = pd.concat([X_train.drop(col, axis=1), train_poly], axis=1)\n","    X_val = pd.concat([X_val.drop(col, axis=1), val_poly], axis=1)\n","\n","print(\"New shape of X_train:\", X_train.shape)\n","print(\"New shape of X_val:\", X_val.shape)"]},{"cell_type":"markdown","metadata":{},"source":["Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>1stFlrSF_Fireplaces</th>\n","      <th>TotalBsmtSF_Fireplaces</th>\n","      <th>...</th>\n","      <th>OverallQual_Fireplaces^2</th>\n","      <th>OverallQual_Fireplaces^3</th>\n","      <th>OverallQual</th>\n","      <th>OverallQual^2</th>\n","      <th>OverallQual^3</th>\n","      <th>OverallQual^4</th>\n","      <th>Fireplaces</th>\n","      <th>Fireplaces^2</th>\n","      <th>Fireplaces^3</th>\n","      <th>Fireplaces^4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>0.800620</td>\n","      <td>0.636004</td>\n","      <td>...</td>\n","      <td>0.009865</td>\n","      <td>0.000980</td>\n","      <td>-0.099842</td>\n","      <td>0.009968</td>\n","      <td>-0.000995</td>\n","      <td>0.000099</td>\n","      <td>-0.994820</td>\n","      <td>0.989667</td>\n","      <td>-0.984540</td>\n","      <td>0.979440</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.638285</td>\n","      <td>-0.833866</td>\n","      <td>...</td>\n","      <td>0.395344</td>\n","      <td>-0.248578</td>\n","      <td>0.632038</td>\n","      <td>0.399472</td>\n","      <td>0.252481</td>\n","      <td>0.159578</td>\n","      <td>-0.994820</td>\n","      <td>0.989667</td>\n","      <td>-0.984540</td>\n","      <td>0.979440</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>0.327296</td>\n","      <td>0.012495</td>\n","      <td>...</td>\n","      <td>0.684614</td>\n","      <td>0.566460</td>\n","      <td>-0.831723</td>\n","      <td>0.691762</td>\n","      <td>-0.575354</td>\n","      <td>0.478535</td>\n","      <td>-0.994820</td>\n","      <td>0.989667</td>\n","      <td>-0.984540</td>\n","      <td>0.979440</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>-0.358127</td>\n","      <td>-0.199366</td>\n","      <td>...</td>\n","      <td>0.239192</td>\n","      <td>-0.116982</td>\n","      <td>-0.831723</td>\n","      <td>0.691762</td>\n","      <td>-0.575354</td>\n","      <td>0.478535</td>\n","      <td>0.588023</td>\n","      <td>0.345772</td>\n","      <td>0.203322</td>\n","      <td>0.119558</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>1.309105</td>\n","      <td>2.518386</td>\n","      <td>...</td>\n","      <td>2.419591</td>\n","      <td>3.763681</td>\n","      <td>-1.563603</td>\n","      <td>2.444854</td>\n","      <td>-3.822780</td>\n","      <td>5.977310</td>\n","      <td>-0.994820</td>\n","      <td>0.989667</td>\n","      <td>-0.984540</td>\n","      <td>0.979440</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 27 columns</p>\n","</div>"],"text/plain":["    LotArea  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  GrLivArea  \\\n","0 -0.114710    -0.509252    -0.639316 -0.804789  1.261552   0.499114   \n","1 -0.176719    -0.509252     0.838208  0.641608 -0.808132  -0.247249   \n","2 -0.246336     1.304613    -0.012560 -0.329000 -0.808132  -0.944766   \n","3 -0.378617     1.304613    -0.339045 -0.609036 -0.808132  -1.146010   \n","4 -0.010898     1.304613    -2.531499 -1.315922  0.550523  -0.481708   \n","\n","   TotRmsAbvGrd  GarageArea  1stFlrSF_Fireplaces  TotalBsmtSF_Fireplaces  ...  \\\n","0      0.250689    0.327629             0.800620                0.636004  ...   \n","1     -0.365525    0.079146            -0.638285               -0.833866  ...   \n","2     -0.981739   -1.105931             0.327296                0.012495  ...   \n","3     -0.981739   -1.134602            -0.358127               -0.199366  ...   \n","4      0.250689   -2.281450             1.309105                2.518386  ...   \n","\n","   OverallQual_Fireplaces^2  OverallQual_Fireplaces^3  OverallQual  \\\n","0                  0.009865                  0.000980    -0.099842   \n","1                  0.395344                 -0.248578     0.632038   \n","2                  0.684614                  0.566460    -0.831723   \n","3                  0.239192                 -0.116982    -0.831723   \n","4                  2.419591                  3.763681    -1.563603   \n","\n","   OverallQual^2  OverallQual^3  OverallQual^4  Fireplaces  Fireplaces^2  \\\n","0       0.009968      -0.000995       0.000099   -0.994820      0.989667   \n","1       0.399472       0.252481       0.159578   -0.994820      0.989667   \n","2       0.691762      -0.575354       0.478535   -0.994820      0.989667   \n","3       0.691762      -0.575354       0.478535    0.588023      0.345772   \n","4       2.444854      -3.822780       5.977310   -0.994820      0.989667   \n","\n","   Fireplaces^3  Fireplaces^4  \n","0     -0.984540      0.979440  \n","1     -0.984540      0.979440  \n","2     -0.984540      0.979440  \n","3      0.203322      0.119558  \n","4     -0.984540      0.979440  \n","\n","[5 rows x 27 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","X_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Full Model R-Squared"]},{"cell_type":"markdown","metadata":{},"source":["Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and validation data."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2, so validation set is 20% of original data"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train R2: 0.7436408980600209\n","Validation R2: 0.7868782847573534\n","Test R2: 0.7878986301832595\n"]}],"source":["# Your code here\n","\n","lr = LinearRegression()\n","lr.fit(X_train, y_train)\n","\n","print(\"Train R2:\", lr.score(X_train, y_train))\n","print(\"Validation R2:\", lr.score(X_val, y_val))\n","print(\"Test R2:\", lr.score(X_test, y_test))\n"]},{"cell_type":"markdown","metadata":{},"source":["It looks like we may be overfitting some now. Let's try some feature selection techniques."]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","\n","First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and validation $R^2$ score and how many features remain."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train R^2: 0.7129424712747777\n","Test R^2:  0.7327039823201675\n","Using 5 out of 10 features\n","\n","Train R^2: 0.7436408980600209\n","Test R^2:  0.7868782847573534\n","Using 10 out of 10 features\n","\n","Train R^2: 0.7436408980600209\n","Test R^2:  0.7868782847573534\n","Using 15 out of 10 features\n","\n","Train R^2: 0.7436408980600209\n","Test R^2:  0.7868782847573534\n","Using 20 out of 10 features\n","\n","Train R^2: 0.7436408980600209\n","Test R^2:  0.7868782847573534\n","Using 25 out of 10 features\n","\n"]}],"source":["# Your code here\n","for n in [5, 10, 15, 20, 25]:\n","    rfe = RFE(LinearRegression(), n_features_to_select=n)\n","    X_rfe_train = rfe.fit_transform(X_train, y_train)\n","    X_rfe_val = rfe.transform(X_val)\n","\n","    lr = LinearRegression()\n","    lr.fit(X_rfe_train, y_train)\n","\n","    print(\"Train R^2:\", lr.score(X_rfe_train, y_train))\n","    print(\"Test R^2: \", lr.score(X_rfe_val, y_val))\n","    print(f\"Using {n} out of {X_train.shape[1]} features\")\n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train R^2: 0.7436408970459523\n","Validation R^2:  0.7868792609246269\n","Using 26 out of 10 features\n","and an alpha of 1\n","\n","Train R^2: 0.7436407999750654\n","Validation R^2:  0.7868900582109771\n","Using 26 out of 10 features\n","and an alpha of 10\n","\n","Train R^2: 0.7436310676380495\n","Validation R^2:  0.7869910954852047\n","Using 26 out of 10 features\n","and an alpha of 100\n","\n","Train R^2: 0.7426575886646019\n","Validation R^2:  0.7873078645406397\n","Using 26 out of 10 features\n","and an alpha of 1000\n","\n","Train R^2: 0.7225260733436096\n","Validation R^2:  0.7726470585701344\n","Using 22 out of 10 features\n","and an alpha of 10000\n","\n"]}],"source":["# Your code here\n","for alpha in [1, 10, 100, 1000, 10000]:\n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X_train, y_train)\n","\n","    print(\"Train R^2:\", lasso.score(X_train, y_train))\n","    print(\"Validation R^2: \", lasso.score(X_val, y_val))\n","    print(f\"Using { 26 - (sum(abs(lasso.coef_) < 10**(-10)))} out of {X_train.shape[1]} features\")\n","    print(\"and an alpha of\", alpha)\n","    print()"]},{"cell_type":"markdown","metadata":{},"source":["Compare the results. Which features would you choose to use?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your written answer here\n","\"\"\"\n","The 17 features selected by Lasso with alpha 1000. \n","This provides a good balance between model complexity (number of features) and performance (R^2 scores).\n","\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Final Model on Test Data\n","\n","### Data Preparation\n","\n","At the start of this lab, we created `X_test` and `y_test`. Prepare `X_test` the same way that `X_train` and `X_val` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1stFlrSF_Fireplaces\n- GarageArea_Fireplaces\n- GrLivArea_Fireplaces\n- OverallQual_Fireplaces\n- OverallQual_TotRmsAbvGrd\n- ...\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-40267f6b9512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Scale X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Add interactions to X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1007\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \"\"\"\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 )\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     def _validate_data(\n","\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1stFlrSF_Fireplaces\n- GarageArea_Fireplaces\n- GrLivArea_Fireplaces\n- OverallQual_Fireplaces\n- OverallQual_TotRmsAbvGrd\n- ...\n"]}],"source":["\n","# Scale X_test\n","X_test_scaled = scaler.transform(X_test)\n","X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n","\n","# Add interactions to X_test\n","for record in top_7:\n","    col1, col2 = record[0]\n","    new_col_name = col1 + \"_\" + col2\n","    X_test[new_col_name] = X_test[col1] * X_test[col2]\n","\n","# Add polynomials to X_val\n","for (col, degree, _) in top_polynomials.values:\n","    poly = PolynomialFeatures(degree, include_bias=False)\n","    poly_test = pd.DataFrame(poly.fit_transform(X_test[[col]]),\n","                                        columns=poly.get_feature_names([col]))\n","    X_test = pd.concat([X_test.drop(col, axis=1), poly_test], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Using either `RFE` or `Lasso`, fit a model on the complete train + validation set, then find R-Squared and MSE values for the test set."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1stFlrSF_Fireplaces\n- GarageArea_Fireplaces\n- GrLivArea_Fireplaces\n- OverallQual_Fireplaces\n- OverallQual_TotRmsAbvGrd\n- ...\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-5395d2b09b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R-Squared:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \"\"\"\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 )\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     def _validate_data(\n","\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- 1stFlrSF_Fireplaces\n- GarageArea_Fireplaces\n- GrLivArea_Fireplaces\n- OverallQual_Fireplaces\n- OverallQual_TotRmsAbvGrd\n- ...\n"]}],"source":["# Your code here\n","final_model = Lasso(alpha=10000)\n","final_model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n","\n","print(\"R-Squared:\", final_model.score(X_test, y_test))\n","print(\"MSE:\", mean_squared_error(y_test, final_model.predict(X_test)))"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up Ideas (Optional)\n","\n","### Create a Lasso Path\n","\n","From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n","\n","https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n","\n","### AIC and BIC for Subset Selection\n","\n","This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n","\n","https://xavierbourretsicotte.github.io/subset_selection.html"]},{"cell_type":"markdown","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}
